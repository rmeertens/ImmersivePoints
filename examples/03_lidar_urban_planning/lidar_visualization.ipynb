{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LiDAR Urban Planning in VR\n",
    "\n",
    "Process and visualize city-scale LiDAR data in virtual reality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Install required packages\n",
    "# !pip install laspy numpy immersivepoints\n",
    "# For LAZ (compressed LAS) support:\n",
    "# !pip install laszip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import laspy\n",
    "import immersivepoints as ip\n",
    "\n",
    "print(\"LiDAR VR Visualization Ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Sample LiDAR Data\n",
    "\n",
    "We'll download a sample LAS file. For real projects, download from:\n",
    "- USGS 3DEP: https://www.usgs.gov/3d-elevation-program\n",
    "- OpenTopography: https://opentopography.org/\n",
    "- Your local government's GIS portal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "# Sample LiDAR file (small urban area)\n",
    "sample_url = \"https://github.com/ASPRSorg/LAS/raw/master/test/simple.las\"\n",
    "sample_file = \"sample_lidar.las\"\n",
    "\n",
    "if not os.path.exists(sample_file):\n",
    "    print(f\"Downloading sample LiDAR data...\")\n",
    "    response = requests.get(sample_url)\n",
    "    with open(sample_file, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "    print(f\"Downloaded {len(response.content)/1024:.1f} KB\")\n",
    "else:\n",
    "    print(f\"Using existing {sample_file}\")\n",
    "\n",
    "# Or use your own file:\n",
    "# sample_file = \"path/to/your/lidar_file.las\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Inspect LiDAR Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(f\"Loading {sample_file}...\")\n",
    "las = laspy.read(sample_file)\n",
    "\n",
    "print(f\"\\nLiDAR File Information:\")\n",
    "print(f\"  Points: {len(las.points):,}\")\n",
    "print(f\"  Format: LAS {las.header.version}\")\n",
    "print(f\"  Point format: {las.header.point_format}\")\n",
    "print(f\"\\nBounding Box:\")\n",
    "print(f\"  X: [{las.header.mins[0]:.2f}, {las.header.maxs[0]:.2f}]\")\n",
    "print(f\"  Y: [{las.header.mins[1]:.2f}, {las.header.maxs[1]:.2f}]\")\n",
    "print(f\"  Z: [{las.header.mins[2]:.2f}, {las.header.maxs[2]:.2f}]\")\n",
    "\n",
    "# Extract coordinates\n",
    "x = las.x\n",
    "y = las.y\n",
    "z = las.z\n",
    "\n",
    "print(f\"\\nAvailable fields: {list(las.point_format.dimension_names)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsample for VR Performance\n",
    "\n",
    "LiDAR files often have millions of points. We'll subsample to 100K-500K for smooth VR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def subsample_lidar(x, y, z, target_points=200000):\n",
    "    \"\"\"\n",
    "    Intelligently subsample LiDAR data.\n",
    "    \"\"\"\n",
    "    n_points = len(x)\n",
    "    \n",
    "    if n_points <= target_points:\n",
    "        print(f\"No subsampling needed ({n_points} points)\")\n",
    "        return x, y, z, np.arange(n_points)\n",
    "    \n",
    "    # Calculate sampling ratio\n",
    "    ratio = target_points / n_points\n",
    "    print(f\"Subsampling {n_points:,} points to ~{target_points:,} ({ratio*100:.1f}%)\")\n",
    "    \n",
    "    # Random sampling\n",
    "    indices = np.random.choice(n_points, size=target_points, replace=False)\n",
    "    indices.sort()  # Keep some spatial coherence\n",
    "    \n",
    "    return x[indices], y[indices], z[indices], indices\n",
    "\n",
    "x_sub, y_sub, z_sub, indices = subsample_lidar(x, y, z, target_points=200000)\n",
    "print(f\"Subsampled to {len(x_sub):,} points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color Coding Options\n",
    "\n",
    "### Option 1: Color by Height (Elevation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def color_by_height(z, colormap='rainbow'):\n",
    "    \"\"\"\n",
    "    Color points by elevation.\n",
    "    \"\"\"\n",
    "    z_norm = (z - z.min()) / (z.max() - z.min())\n",
    "    \n",
    "    if colormap == 'rainbow':\n",
    "        # Blue (low) -> Green -> Yellow -> Red (high)\n",
    "        hue = 0.7 - (z_norm * 0.7)  # 0.7 to 0.0\n",
    "    elif colormap == 'terrain':\n",
    "        # Blue (water) -> Green (land) -> Brown (mountains)\n",
    "        hue = np.where(z_norm < 0.3, 0.6,  # Blue for low\n",
    "               np.where(z_norm < 0.7, 0.33,  # Green for mid\n",
    "                        0.08))  # Brown for high\n",
    "    else:\n",
    "        hue = z_norm\n",
    "    \n",
    "    return hue\n",
    "\n",
    "hue_height = color_by_height(z_sub, colormap='rainbow')\n",
    "print(f\"Colored {len(hue_height):,} points by elevation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Color by LiDAR Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def color_by_classification(las, indices):\n",
    "    \"\"\"\n",
    "    Color by LiDAR classification codes.\n",
    "    Standard classes: 2=Ground, 3=Low vegetation, 4=Med vegetation,\n",
    "                     5=High vegetation, 6=Building, 9=Water\n",
    "    \"\"\"\n",
    "    try:\n",
    "        classification = las.classification[indices]\n",
    "        \n",
    "        class_colors = {\n",
    "            0: 0.5,   # Never classified - white\n",
    "            1: 0.5,   # Unclassified - white\n",
    "            2: 0.08,  # Ground - brown\n",
    "            3: 0.33,  # Low vegetation - green\n",
    "            4: 0.33,  # Medium vegetation - green\n",
    "            5: 0.33,  # High vegetation - green\n",
    "            6: 0.0,   # Building - red/gray\n",
    "            7: 0.0,   # Noise - dark\n",
    "            9: 0.6,   # Water - blue\n",
    "            17: 0.7,  # Bridge - blue-cyan\n",
    "        }\n",
    "        \n",
    "        hue = np.array([class_colors.get(c, 0.5) for c in classification])\n",
    "        print(f\"Classification classes found: {np.unique(classification)}\")\n",
    "        return hue\n",
    "    \n",
    "    except:\n",
    "        print(\"No classification data available, using height instead\")\n",
    "        return color_by_height(z_sub)\n",
    "\n",
    "hue_class = color_by_classification(las, indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 3: Color by Intensity (Reflectivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def color_by_intensity(las, indices):\n",
    "    \"\"\"\n",
    "    Color by LiDAR return intensity.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        intensity = las.intensity[indices]\n",
    "        intensity_norm = (intensity - intensity.min()) / (intensity.max() - intensity.min())\n",
    "        \n",
    "        # Grayscale: 0.0 (red/dark) to 0.0 (bright)\n",
    "        # Actually map to hue for visibility\n",
    "        hue = intensity_norm * 0.5  # 0 to 0.5 (dark to light)\n",
    "        \n",
    "        print(f\"Intensity range: {intensity.min()} to {intensity.max()}\")\n",
    "        return hue\n",
    "    except:\n",
    "        print(\"No intensity data available\")\n",
    "        return color_by_height(z_sub)\n",
    "\n",
    "hue_intensity = color_by_intensity(las, indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Point Cloud for VR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Choose your color scheme (uncomment one):\n",
    "hue = hue_height       # Color by elevation\n",
    "# hue = hue_class      # Color by classification\n",
    "# hue = hue_intensity  # Color by intensity\n",
    "\n",
    "# Center the data\n",
    "x_centered = x_sub - x_sub.mean()\n",
    "y_centered = y_sub - y_sub.mean()\n",
    "z_centered = z_sub - z_sub.min()  # Ground at Z=0\n",
    "\n",
    "# Scale for VR (LiDAR coordinates are often in meters)\n",
    "# Scale down so 1 meter = 0.01 VR units (makes large scenes manageable)\n",
    "scale = 0.01\n",
    "x_vr = x_centered * scale\n",
    "y_vr = y_centered * scale\n",
    "z_vr = z_centered * scale\n",
    "\n",
    "# Create XYZI array\n",
    "points = np.column_stack([x_vr, y_vr, z_vr, hue]).astype(np.float32)\n",
    "\n",
    "print(f\"\\nVR Point Cloud:\")\n",
    "print(f\"  Points: {len(points):,}\")\n",
    "print(f\"  VR Size: X=[{x_vr.min():.1f}, {x_vr.max():.1f}] \"\n",
    "      f\"Y=[{y_vr.min():.1f}, {y_vr.max():.1f}] \"\n",
    "      f\"Z=[{z_vr.min():.1f}, {z_vr.max():.1f}]\")\n",
    "print(f\"  Real Size: ~{(x_sub.max()-x_sub.min()):.0f}m Ã— {(y_sub.max()-y_sub.min()):.0f}m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize in Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "ip.renderPoints(points, point_size=0.02, background_color=0x87CEEB, show_axes=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate VR Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "ip.showVR(points, point_size=0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save for Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "output_file = \"lidar_urban_scene.xyzi\"\n",
    "points.astype(np.float32).byteswap().tofile(output_file)\n",
    "\n",
    "print(f\"Saved to {output_file}\")\n",
    "print(f\"File size: {len(points) * 16 / (1024*1024):.1f} MB\")\n",
    "print(f\"\\nUpload at: https://immersivepoints.com/upload.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tips for Large Datasets\n",
    "\n",
    "**If your LAS file is huge (>100MB):**\n",
    "\n",
    "1. **Spatial crop**: Only load points in your area of interest\n",
    "```python\n",
    "# Crop to bounding box\n",
    "xmin, xmax = 500000, 501000  # Adjust to your coordinates\n",
    "ymin, ymax = 4000000, 4001000\n",
    "mask = (x > xmin) & (x < xmax) & (y > ymin) & (y < ymax)\n",
    "x_crop = x[mask]\n",
    "y_crop = y[mask]\n",
    "z_crop = z[mask]\n",
    "```\n",
    "\n",
    "2. **Aggressive subsampling**: Keep only 1:100 or 1:200 points\n",
    "\n",
    "3. **Ground removal**: Filter out ground points to focus on buildings\n",
    "```python\n",
    "# Keep only non-ground points\n",
    "if hasattr(las, 'classification'):\n",
    "    non_ground = las.classification != 2\n",
    "    x = x[non_ground]\n",
    "    y = y[non_ground]\n",
    "    z = z[non_ground]\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
