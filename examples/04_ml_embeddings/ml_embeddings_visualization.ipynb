{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing ML Embeddings in VR\n",
    "\n",
    "Explore high-dimensional embeddings in 3D space using t-SNE, UMAP, or PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Alternative: Manual installation (uncomment if needed)\n# !pip install numpy scikit-learn umap-learn matplotlib immersivepoints"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Auto-install immersivepoints in the current kernel\nimport sys\nimport subprocess\nimport importlib\n\ntry:\n    import immersivepoints as ip\nexcept ImportError:\n    print(\"Installing immersivepoints...\")\n    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'immersivepoints', '--quiet'])\n    import site\n    importlib.reload(site)\n    import immersivepoints as ip\n    print(\"✓ Installation complete!\")\n\n# Other imports\nimport numpy as np\nfrom sklearn.datasets import load_digits\nfrom sklearn.manifold import TSNE\nfrom sklearn.decomposition import PCA\n\ntry:\n    import umap\nexcept ImportError:\n    print(\"UMAP not installed. Installing...\")\n    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'umap-learn', '--quiet'])\n    import site\n    importlib.reload(site)\n    import umap\n\nprint(\"✓ ML Embedding VR Visualization Ready!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "\n",
    "We'll start with the scikit-learn digits dataset (1797 samples, 64 dimensions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load digits dataset (small version of MNIST)\n",
    "digits = load_digits()\n",
    "X = digits.data  # 1797 samples × 64 features\n",
    "y = digits.target  # Labels 0-9\n",
    "\n",
    "print(f\"Dataset shape: {X.shape}\")\n",
    "print(f\"Number of classes: {len(np.unique(y))}\")\n",
    "print(f\"Samples per class: {np.bincount(y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option to Load MNIST (Full Dataset)\n",
    "\n",
    "Uncomment to use full MNIST (70,000 samples). **Warning: t-SNE will be slow!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.datasets import fetch_openml\n",
    "# print(\"Downloading MNIST... this may take a minute\")\n",
    "# mnist = fetch_openml('mnist_784', parser='auto')\n",
    "# X = mnist.data[:10000]  # Use subset for speed\n",
    "# y = mnist.target[:10000].astype(int)\n",
    "# print(f\"Loaded {len(X)} MNIST samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce to 3D - Method 1: PCA (Fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running PCA to reduce to 3D...\")\n",
    "pca = PCA(n_components=3)\n",
    "X_3d_pca = pca.fit_transform(X)\n",
    "\n",
    "explained_var = pca.explained_variance_ratio_.sum()\n",
    "print(f\"PCA complete! Explained variance: {explained_var*100:.1f}%\")\n",
    "print(f\"Shape: {X_3d_pca.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce to 3D - Method 2: t-SNE (Better, Slower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running t-SNE to reduce to 3D...\")\n",
    "print(\"This may take 30-120 seconds depending on dataset size\")\n",
    "\n",
    "tsne = TSNE(n_components=3, random_state=42, perplexity=30, n_iter=1000)\n",
    "X_3d_tsne = tsne.fit_transform(X)\n",
    "\n",
    "print(f\"t-SNE complete!\")\n",
    "print(f\"Shape: {X_3d_tsne.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce to 3D - Method 3: UMAP (Best of Both Worlds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if umap is not None:\n",
    "    print(\"Running UMAP to reduce to 3D...\")\n",
    "    reducer = umap.UMAP(n_components=3, random_state=42, n_neighbors=15)\n",
    "    X_3d_umap = reducer.fit_transform(X)\n",
    "    print(f\"UMAP complete!\")\n",
    "    print(f\"Shape: {X_3d_umap.shape}\")\n",
    "else:\n",
    "    print(\"UMAP not available. Using t-SNE instead.\")\n",
    "    X_3d_umap = X_3d_tsne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose Your Embedding Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose which method to visualize:\n",
    "X_3d = X_3d_tsne  # or X_3d_pca or X_3d_umap\n",
    "method_name = \"t-SNE\"\n",
    "\n",
    "print(f\"Using {method_name} embeddings for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color Coding - Option 1: By True Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels_to_hue(labels, n_classes=10):\n",
    "    \"\"\"\n",
    "    Map class labels to evenly spaced hues.\n",
    "    \"\"\"\n",
    "    hue = (labels / n_classes) * 0.9  # 0 to 0.9 to avoid red wrapping\n",
    "    return hue\n",
    "\n",
    "hue_labels = labels_to_hue(y, n_classes=len(np.unique(y)))\n",
    "print(f\"Colored {len(hue_labels)} points by class label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color Coding - Option 2: By Prediction Correctness\n",
    "\n",
    "Train a simple classifier and visualize errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "print(\"Training classifier to find misclassifications...\")\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "y_pred = cross_val_predict(clf, X, y, cv=3)\n",
    "\n",
    "# Color: green for correct, red for wrong\n",
    "correct = (y == y_pred)\n",
    "hue_correctness = np.where(correct, 0.33, 0.0)  # Green or Red\n",
    "\n",
    "accuracy = correct.mean()\n",
    "print(f\"Classifier accuracy: {accuracy*100:.1f}%\")\n",
    "print(f\"Misclassifications: {(~correct).sum()} / {len(y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color Coding - Option 3: By Prediction Confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get prediction probabilities\n",
    "clf_full = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf_full.fit(X, y)\n",
    "y_proba = clf_full.predict_proba(X)\n",
    "confidence = y_proba.max(axis=1)\n",
    "\n",
    "# Map confidence to hue (low=red, high=blue)\n",
    "hue_confidence = confidence * 0.6  # 0 (red) to 0.6 (blue)\n",
    "\n",
    "print(f\"Confidence range: [{confidence.min():.2f}, {confidence.max():.2f}]\")\n",
    "print(f\"Low confidence (<0.7) points: {(confidence < 0.7).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Points for VR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose color scheme (uncomment one):\n",
    "hue = hue_labels         # By class labels\n",
    "# hue = hue_correctness  # By prediction correctness\n",
    "# hue = hue_confidence   # By prediction confidence\n",
    "\n",
    "# Normalize and center the 3D embedding\n",
    "X_norm = X_3d - X_3d.mean(axis=0)\n",
    "X_norm = X_norm / X_norm.std() * 5  # Scale to reasonable VR size\n",
    "\n",
    "# Create point cloud\n",
    "points = np.column_stack([X_norm[:, 0], X_norm[:, 1], X_norm[:, 2], hue])\n",
    "points = points.astype(np.float32)\n",
    "\n",
    "print(f\"\\nPoint cloud ready:\")\n",
    "print(f\"  Points: {len(points):,}\")\n",
    "print(f\"  Bounding box: [{X_norm.min():.1f}, {X_norm.max():.1f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize in Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip.renderPoints(points, point_size=0.08, background_color=0x1a1a1a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate VR Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip.showVR(points, point_size=0.08)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis: Find Interesting Patterns\n",
    "\n",
    "Let's identify some interesting regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find most confused points\n",
    "if 'confidence' in locals():\n",
    "    uncertain_idx = confidence.argsort()[:20]  # 20 most uncertain\n",
    "    print(\"Most uncertain predictions:\")\n",
    "    for i in uncertain_idx[:10]:\n",
    "        print(f\"  Sample {i}: True={y[i]}, Pred={y_pred[i]}, Confidence={confidence[i]:.2f}\")\n",
    "\n",
    "# Find largest clusters per class\n",
    "print(\"\\nClass distribution in embedding space:\")\n",
    "for class_id in range(len(np.unique(y))):\n",
    "    class_mask = (y == class_id)\n",
    "    class_center = X_norm[class_mask].mean(axis=0)\n",
    "    class_spread = X_norm[class_mask].std(axis=0).mean()\n",
    "    print(f\"  Class {class_id}: center={class_center}, spread={class_spread:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save for Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = f\"ml_embeddings_{method_name.lower()}.xyzi\"\n",
    "points.astype(np.float32).byteswap().tofile(output_file)\n",
    "\n",
    "print(f\"Saved to {output_file}\")\n",
    "print(f\"File size: {len(points) * 16 / 1024:.1f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What to Look For in VR\n",
    "\n",
    "When exploring embeddings in VR:\n",
    "\n",
    "1. **Cluster Separation**: Are different classes well-separated?\n",
    "2. **Misclassification Patterns**: Do errors cluster together?\n",
    "3. **Outliers**: Isolated points far from their class cluster\n",
    "4. **Uncertain Regions**: Boundaries where classes overlap\n",
    "5. **Sub-clusters**: Multiple groups within same class (e.g., different handwriting styles)\n",
    "\n",
    "**Try This**:\n",
    "- Walk to a red point (misclassification) and see what surrounds it\n",
    "- Find the boundary between two classes\n",
    "- Look for outliers (points far from their cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}